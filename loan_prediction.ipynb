{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551f48d0-2ec0-42d8-9a74-26d8805aea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58645 entries, 0 to 58644\n",
      "Data columns (total 13 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          58645 non-null  int64  \n",
      " 1   person_age                  58645 non-null  int64  \n",
      " 2   person_income               58645 non-null  int64  \n",
      " 3   person_home_ownership       58645 non-null  object \n",
      " 4   person_emp_length           58645 non-null  float64\n",
      " 5   loan_intent                 58645 non-null  object \n",
      " 6   loan_grade                  58645 non-null  object \n",
      " 7   loan_amnt                   58645 non-null  int64  \n",
      " 8   loan_int_rate               58645 non-null  float64\n",
      " 9   loan_percent_income         58645 non-null  float64\n",
      " 10  cb_person_default_on_file   58645 non-null  object \n",
      " 11  cb_person_cred_hist_length  58645 non-null  int64  \n",
      " 12  loan_status                 58645 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(4)\n",
      "memory usage: 5.8+ MB\n",
      "None\n",
      "\n",
      "Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39098 entries, 0 to 39097\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          39098 non-null  int64  \n",
      " 1   person_age                  39098 non-null  int64  \n",
      " 2   person_income               39098 non-null  int64  \n",
      " 3   person_home_ownership       39098 non-null  object \n",
      " 4   person_emp_length           39098 non-null  float64\n",
      " 5   loan_intent                 39098 non-null  object \n",
      " 6   loan_grade                  39098 non-null  object \n",
      " 7   loan_amnt                   39098 non-null  int64  \n",
      " 8   loan_int_rate               39098 non-null  float64\n",
      " 9   loan_percent_income         39098 non-null  float64\n",
      " 10  cb_person_default_on_file   39098 non-null  object \n",
      " 11  cb_person_cred_hist_length  39098 non-null  int64  \n",
      "dtypes: float64(3), int64(5), object(4)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "Validation AUC Score: 0.9370251648659101\n",
      "Submission file created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the base directory as the current working directory\n",
    "BASE_DIR = os.getcwd()  # This gets the current working directory\n",
    "train_file = os.path.join(BASE_DIR, 'train.csv')\n",
    "test_file = os.path.join(BASE_DIR, 'test.csv')\n",
    "sample_submission_file = os.path.join(BASE_DIR, 'sample_submission.csv')\n",
    "\n",
    "# Load train and test data\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "\n",
    "# Step 1: Data Exploration\n",
    "print(\"Train Data Info:\")\n",
    "print(train_data.info())\n",
    "print(\"\\nTest Data Info:\")\n",
    "print(test_data.info())\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "\n",
    "# Separate the target from the train dataset\n",
    "X = train_data.drop(columns=['loan_status'])  # Features\n",
    "y = train_data['loan_status']  # Target\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessing for numeric data (imputation and scaling)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Impute missing values with median\n",
    "    ('scaler', StandardScaler())  # Scale numeric features\n",
    "])\n",
    "\n",
    "# Define preprocessing for categorical data (imputation and one-hot encoding)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Combine preprocessing for both numeric and categorical features\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "# Step 3: Build pipeline with preprocessing and Random Forest model\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Step 4: Model Training\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = model_pipeline.predict_proba(X_val)[:, 1]\n",
    "auc_score = roc_auc_score(y_val, y_val_pred)\n",
    "print(f\"Validation AUC Score: {auc_score}\")\n",
    "\n",
    "# Step 5: Predict on Test Data\n",
    "\n",
    "# Predict the probabilities for test data\n",
    "test_preds = model_pipeline.predict_proba(test_data)[:, 1]\n",
    "\n",
    "# Step 6: Prepare the Submission File\n",
    "\n",
    "# Load sample submission to get the 'id' column\n",
    "sample_submission = pd.read_csv(sample_submission_file)\n",
    "\n",
    "# Prepare the final submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': sample_submission['id'],\n",
    "    'loan_status': test_preds\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv(os.path.join(BASE_DIR, 'submission_final.csv'), index=False)\n",
    "print(\"Submission file created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9ae93-dd6b-4a29-a567-9d663e3a04ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7445671-a670-4ee4-a2cf-5d55c98593ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
